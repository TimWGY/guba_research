{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Chinese Stock Message Board Post Sentiment with Tensorflow - V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependencies**  \n",
    "numpy  \n",
    "jieba  \n",
    "gensim  \n",
    "tensorflow  \n",
    "matplotlib  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import jieba # for Chinese tokenization\n",
    "# gensim for loading pre-trained word vector\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# for decompression\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References\n",
    "# https://github.com/aespresso/chinese_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source of Pretrained Word Embedding**  \n",
    "https://github.com/Embedding/Chinese-Word-Vectors  \n",
    "Finance news domain-specific word embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the bz2 file should be in the directory named embeddings\n",
    "# with open(\"embeddings/sgns.  .bigram\", 'wb') as new_file, open(\"embeddings/sgns.  .bigram.bz2\", 'rb') as file:\n",
    "#     decompressor = bz2.BZ2Decompressor()\n",
    "#     for data in iter(lambda : file.read(100 * 1024), b''):\n",
    "#         new_file.write(decompressor.decompress(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gensim to load pre-trained embedding\n",
    "cn_model = KeyedVectors.load_word2vec_format('embeddings/sgns.financial.bigram-char', \n",
    "                                             binary=False, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of word embedding is 300.\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = cn_model['慢'].shape[0]\n",
    "print('The length of word embedding is {}.'.format(embedding_dim))\n",
    "# cn_model['慢']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity for Vector Space Models by Christian S. Perone\n",
    "# http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/\n",
    "# similarity of two words\n",
    "# cn_model.similarity('做空', '买')\n",
    "# np.dot(cn_model['反弹']/np.linalg.norm(cn_model['反弹']), \n",
    "# cn_model['涨']/np.linalg.norm(cn_model['涨']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('暴跌', 0.7939429879188538),\n",
       " ('重挫', 0.7413685321807861),\n",
       " ('下挫', 0.7085591554641724),\n",
       " ('下跌', 0.704810619354248),\n",
       " ('急跌', 0.7006838321685791),\n",
       " ('跳水', 0.658748984336853),\n",
       " ('挫', 0.6519291996955872),\n",
       " ('跌', 0.6498780250549316),\n",
       " ('暴涨', 0.6183834075927734),\n",
       " ('涨', 0.6176421642303467)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find most similar words to a keyword\n",
    "cn_model.most_similar(positive=['大跌'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among 反弹 大跌 下探 下挫 暴跌 亏损:\n",
      "亏损 is different from others.\n"
     ]
    }
   ],
   "source": [
    "# find word that doesn't belong to the category in a list\n",
    "test_words = '反弹 大跌 下探 下挫 暴跌 亏损'\n",
    "test_words_result = cn_model.doesnt_match(test_words.split())\n",
    "print('Among '+test_words+':\\n%s is different from others.' %test_words_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('强烈推荐', 0.419800341129303)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concept pairing \n",
    "cn_model.most_similar(positive=['韭菜','买入'], negative=['庄家'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the hand-labeled stock message board data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data_1 = pd.read_csv('data/sentiment_data_1.csv')\n",
    "sentiment_data_1.sentiment = sentiment_data_1.sentiment.apply(int)\n",
    "sentiment_data_1.sentiment = sentiment_data_1.sentiment.apply(lambda x: x if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data_1 = sentiment_data_1.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3727"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(sentiment_data_1['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sentiment_data_1[sentiment_data_1['sentiment']==1][:3720].append(sentiment_data_1[sentiment_data_1['sentiment']==0][:3720], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['title_body'] = dataset['post_title'] + dataset['post_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7440\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_orig = dataset['title_body'].to_list()\n",
    "train_target = dataset['sentiment'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tensorflow APIs\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM, Bidirectional\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word cut and tokenization**  \n",
    "Remove punctuation, use jieba to cut words, turn resulting generator into list, index the words according to loaded pre-trained embeddings. In the end, each post will be turned into a list of indices, with each index corresponding to the word in the embedding matrix. The indice-list represenation of posts are stored in train_tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /anaconda3/lib/python3.6/site-packages/jieba/dict.txt ...\n",
      "Loading model from cache /var/folders/lv/brdmj4x916vdfmgkd6k2s_3r0000gn/T/jieba.cache\n",
      "Loading model cost 0.9946861267089844 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Use jieba to parse and tokenize texts\n",
    "train_tokens = []\n",
    "for text in train_texts_orig:\n",
    "    # remove punctuations\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    # cut Chinese words with jieba\n",
    "    cut = jieba.cut(text)\n",
    "    # the outcome of jieba is a generator, the line below turns it into a list\n",
    "    cut_list = [ i for i in cut ]\n",
    "    for i, word in enumerate(cut_list):\n",
    "        try:\n",
    "            # turn word into index\n",
    "            cut_list[i] = cn_model.vocab[word].index\n",
    "        except KeyError:\n",
    "            # if word not in dictionary, use 0\n",
    "            cut_list[i] = 0\n",
    "    train_tokens.append(cut_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize Post Index-list**  \n",
    "Posts vary in length. To save computational power and make sure all posts can be coded in the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the length of all posts\n",
    "num_tokens = [ len(tokens) for tokens in train_tokens ]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(num_tokens), bins = 100)\n",
    "plt.xlim((0,10))\n",
    "plt.ylabel('number of tokens')\n",
    "plt.xlabel('length of tokens')\n",
    "plt.title('Distribution of tokens length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming the length follows Guassian distribution...\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964516129032258"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can cover 95% of the posts using 68, thus we can pad the short ones and truncate the long ones\n",
    "np.sum( num_tokens < max_tokens ) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reverse-tokenization**  \n",
    "Define a function to map index to readable text, for debugging purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_tokens(tokens):\n",
    "    text = ''\n",
    "    for i in tokens:\n",
    "        if i != 0:\n",
    "            text = text + cn_model.index2word[i]\n",
    "        else:\n",
    "            text = text + ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse = reverse_tokens(train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # However, punctuations are not retrieved.\n",
    "# reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Comparing to original text\n",
    "# train_texts_orig[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Embedding Matrix**  \n",
    "Keras needs a matrix with dimension $(numwords, embeddingdim)$\n",
    "To save computational power, use the embeddings of only first 100000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 100000\n",
    "# initialize embedding_matrix\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "for i in range(num_words):\n",
    "    embedding_matrix[i,:] = cn_model[cn_model.index2word[i]]\n",
    "embedding_matrix = embedding_matrix.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dimension and value of embedding are correct\n",
    "np.sum( cn_model[cn_model.index2word[333]] == embedding_matrix[333] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding and truncating**  \n",
    "Using 'pre' padding because some empirical studies suggest this practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad_sequences returns a numpy array\n",
    "train_pad = pad_sequences(train_tokens, maxlen=max_tokens,\n",
    "                            padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words not in the first 100000 are represented as 0\n",
    "train_pad[ train_pad>=num_words ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,   303, 14618,\n",
       "        1413,   303, 14618,  1413,   303, 14618,  1413,   776, 19364,\n",
       "        9352, 82709,     0,   634,  1553, 24506,   104,     0, 22744,\n",
       "         125,   112,   303, 14618,  1413,   303, 14618,  1413,   303,\n",
       "       14618,  1413,   776, 19364,  9352, 82709,     0,   634,  1553,\n",
       "       24506,   104,     0, 22744,   125,   190,     0, 22744,    28,\n",
       "       34824,  8371,     0,  8562,   907,   448,   669,     0,   849,\n",
       "           0,  2129,   809,     0,  1467], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "train_pad[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare target vector，first half are 1 (positive) second half are 0 (negative)\n",
    "train_target = np.array(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_target[len(train_target)//2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90% as training，10% as testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_pad,\n",
    "                                                    train_target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  上证指数3500左右震荡有望再 下走3450周一抄底周二周三   上证指数3500左右震荡有望再 下走3450周一抄底周二周三 多观望周四 短线获利落袋为安周四尾盘或周五注意风险\n",
      "class:  0\n"
     ]
    }
   ],
   "source": [
    "# checking training set \n",
    "print('text: ',reverse_tokens(X_train[35]).strip())\n",
    "print('class: ',y_train[35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start building model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding layer input: $$(batchsize, maxtokens)$$\n",
    "Embedding layer ouput: $$(batchsize, maxtokens, embeddingdim)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(num_words,\n",
    "                    embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_tokens,\n",
    "                    trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Bidirectional(LSTM(units=64, return_sequences=True)))\n",
    "model.add(LSTM(units=16, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units=32, return_sequences=True))\n",
    "model.add(GRU(units=16, return_sequences=True))\n",
    "model.add(GRU(units=4, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 68, 300)           30000000  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 68, 128)           186880    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 68, 16)            9280      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 68, 32)            4704      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 68, 16)            2352      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 4)                 252       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 30,203,473\n",
      "Trainable params: 203,473\n",
      "Non-trainable params: 30,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# structure of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighting storage\n",
    "path_checkpoint = 'sentiment_checkpoint.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=path_checkpoint, monitor='val_loss',\n",
    "                                      verbose=1, save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to open file (unable to open file: name = 'sentiment_checkpoint.keras', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
     ]
    }
   ],
   "source": [
    "# try_loading_pretrained_model\n",
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stoping if validation loss doesn't improve in 3 epochs\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decreasing learning rate\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1, min_lr=1e-8, patience=0,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback functions\n",
    "callbacks = [\n",
    "    earlystopping, \n",
    "    checkpoint,\n",
    "    lr_reduction\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5356 samples, validate on 596 samples\n",
      "Epoch 1/20\n",
      "5248/5356 [============================>.] - ETA: 1s - loss: 0.5462 - accuracy: 0.7222\n",
      "Epoch 00001: val_loss improved from inf to 0.40407, saving model to sentiment_checkpoint.keras\n",
      "5356/5356 [==============================] - 58s 11ms/sample - loss: 0.5427 - accuracy: 0.7248 - val_loss: 0.4041 - val_accuracy: 0.8289\n",
      "Epoch 2/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.3975 - accuracy: 0.8357\n",
      "Epoch 00002: val_loss improved from 0.40407 to 0.36268, saving model to sentiment_checkpoint.keras\n",
      "5356/5356 [==============================] - 36s 7ms/sample - loss: 0.3980 - accuracy: 0.8355 - val_loss: 0.3627 - val_accuracy: 0.8557\n",
      "Epoch 3/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.8639\n",
      "Epoch 00003: val_loss improved from 0.36268 to 0.34075, saving model to sentiment_checkpoint.keras\n",
      "5356/5356 [==============================] - 33s 6ms/sample - loss: 0.3475 - accuracy: 0.8639 - val_loss: 0.3407 - val_accuracy: 0.8624\n",
      "Epoch 4/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.3232 - accuracy: 0.8775\n",
      "Epoch 00004: val_loss improved from 0.34075 to 0.33646, saving model to sentiment_checkpoint.keras\n",
      "5356/5356 [==============================] - 31s 6ms/sample - loss: 0.3232 - accuracy: 0.8773 - val_loss: 0.3365 - val_accuracy: 0.8624\n",
      "Epoch 5/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.2830 - accuracy: 0.8971\n",
      "Epoch 00005: val_loss improved from 0.33646 to 0.32792, saving model to sentiment_checkpoint.keras\n",
      "5356/5356 [==============================] - 34s 6ms/sample - loss: 0.2844 - accuracy: 0.8966 - val_loss: 0.3279 - val_accuracy: 0.8641\n",
      "Epoch 6/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.2691 - accuracy: 0.9057\n",
      "Epoch 00006: val_loss did not improve from 0.32792\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "5356/5356 [==============================] - 32s 6ms/sample - loss: 0.2706 - accuracy: 0.9055 - val_loss: 0.3570 - val_accuracy: 0.8389\n",
      "Epoch 7/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.2382 - accuracy: 0.9224\n",
      "Epoch 00007: val_loss did not improve from 0.32792\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "5356/5356 [==============================] - 30s 6ms/sample - loss: 0.2380 - accuracy: 0.9225 - val_loss: 0.3290 - val_accuracy: 0.8742\n",
      "Epoch 8/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.9301\n",
      "Epoch 00008: val_loss improved from 0.32792 to 0.32444, saving model to sentiment_checkpoint.keras\n",
      "5356/5356 [==============================] - 31s 6ms/sample - loss: 0.2196 - accuracy: 0.9305 - val_loss: 0.3244 - val_accuracy: 0.8775\n",
      "Epoch 9/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.2188 - accuracy: 0.9314\n",
      "Epoch 00009: val_loss did not improve from 0.32444\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "5356/5356 [==============================] - 36s 7ms/sample - loss: 0.2181 - accuracy: 0.9313 - val_loss: 0.3252 - val_accuracy: 0.8775\n",
      "Epoch 10/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9312\n",
      "Epoch 00010: val_loss did not improve from 0.32444\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "5356/5356 [==============================] - 33s 6ms/sample - loss: 0.2171 - accuracy: 0.9311 - val_loss: 0.3252 - val_accuracy: 0.8775\n",
      "Epoch 11/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.2150 - accuracy: 0.9322\n",
      "Epoch 00011: val_loss did not improve from 0.32444\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "5356/5356 [==============================] - 31s 6ms/sample - loss: 0.2170 - accuracy: 0.9315 - val_loss: 0.3252 - val_accuracy: 0.8775\n",
      "Epoch 12/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.2158 - accuracy: 0.9318\n",
      "Epoch 00012: val_loss did not improve from 0.32444\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "5356/5356 [==============================] - 27s 5ms/sample - loss: 0.2170 - accuracy: 0.9315 - val_loss: 0.3252 - val_accuracy: 0.8775\n",
      "Epoch 13/20\n",
      "5248/5356 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9316\n",
      "Epoch 00013: val_loss did not improve from 0.32444\n",
      "5356/5356 [==============================] - 28s 5ms/sample - loss: 0.2170 - accuracy: 0.9315 - val_loss: 0.3252 - val_accuracy: 0.8775\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x180f99fd0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start fitting\n",
    "model.fit(X_train, y_train,\n",
    "          validation_split=0.1, \n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate with test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1488/1488 [==============================] - 3s 2ms/sample - loss: 0.3508 - accuracy: 0.8542\n",
      "Accuracy:85.42%\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test)\n",
    "print('Accuracy:{0:.2%}'.format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, return_proba = False):\n",
    "    if not return_proba:\n",
    "        print(text)\n",
    "    # remove punctuations\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    # cut words\n",
    "    cut = jieba.cut(text)\n",
    "    cut_list = [ i for i in cut ]\n",
    "    # tokenize\n",
    "    for i, word in enumerate(cut_list):\n",
    "        try:\n",
    "            cut_list[i] = cn_model.vocab[word].index\n",
    "            if cut_list[i] >= 100000:\n",
    "                cut_list[i] = 0\n",
    "        except KeyError:\n",
    "            cut_list[i] = 0\n",
    "    # padding\n",
    "    tokens_pad = pad_sequences([cut_list], maxlen=max_tokens,\n",
    "                           padding='pre', truncating='pre')\n",
    "    # prediction\n",
    "    result = model.predict(x=tokens_pad)\n",
    "    coef = result[0][0]\n",
    "    \n",
    "    if return_proba:\n",
    "        return coef\n",
    "    \n",
    "    if coef >= 0.5:\n",
    "        print('postive','output=%.2f'%coef)\n",
    "    else:\n",
    "        print('negative','output=%.2f'%coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无量上涨，冲高回落\n",
      "postive output=0.85\n",
      "大盘已经跌到底了，散户们冲啊抄底\n",
      "postive output=0.89\n",
      "为国护盘，坚定持有\n",
      "postive output=0.91\n",
      "吧里的多头去哪里了呢\n",
      "negative output=0.36\n",
      "这轮反弹即将结束，建议大家逢高撤出\n",
      "postive output=0.91\n",
      "明显是庄家诱多，傻散才会抄底呢[傲]\n",
      "postive output=0.93\n",
      "明天开盘大涨，打爆这些空头\n",
      "negative output=0.20\n"
     ]
    }
   ],
   "source": [
    "test_list = [\n",
    "    '无量上涨，冲高回落',\n",
    "    '大盘已经跌到底了，散户们冲啊抄底',\n",
    "    '为国护盘，坚定持有',\n",
    "    '吧里的多头去哪里了呢',\n",
    "    '这轮反弹即将结束，建议大家逢高撤出',\n",
    "    '明显是庄家诱多，傻散才会抄底呢[傲]',\n",
    "    '明天开盘大涨，打爆这些空头'\n",
    "]\n",
    "for text in test_list:\n",
    "    predict_sentiment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Misclassified posts**<br>\n",
    "The concept of '反弹' is not properly learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = y_pred.T[0]\n",
    "y_pred = [1 if p>= 0.5 else 0 for p in y_pred]\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified = np.where( y_pred != y_actual )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/1488\n"
     ]
    }
   ],
   "source": [
    "print(len(misclassified),end='/')\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "久违的逼空光头大阳盼来了久违的逼空光头大阳盼来了\n",
      "预测的分类 1\n",
      "实际的分类 0\n"
     ]
    }
   ],
   "source": [
    "# example of misclassified\n",
    "idx = misclassified[2]\n",
    "print(reverse_tokens(X_test[idx]).strip())\n",
    "print('预测的分类', y_pred[idx])\n",
    "print('实际的分类', y_actual[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       市场资金正在从高价股转向低价股关注600512腾达建设浙江板块工程建设板块市场资金正在从高价股转向低价股关注600512腾达建设浙江板块工程建设板块双料低价冠军后续订单 定向增发停牌重组可期股价528元\n",
      "预测的分类 0\n",
      "实际的分类 0\n"
     ]
    }
   ],
   "source": [
    "# example of correcetly classified\n",
    "idx=1\n",
    "print(reverse_tokens(X_test[idx]).strip())\n",
    "print('预测的分类', y_pred[idx])\n",
    "print('实际的分类', y_actual[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180f99860>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzt3Xl8VfWd//HXJzf7HpKAkAABRAVkNahAteDSYrWitbhM21GmLT/HOnVqO462ju1YZ0anrTPa6lSmtW5Tca2ldWst7kAFFUFW2YSwhkA2siff3x/nJrmEQC5wc8/N5f18PM7j3nvu957z4dS+OXzP93yPOecQEZH4kuB3ASIiEnkKdxGROKRwFxGJQwp3EZE4pHAXEYlDCncRkTikcBcRiUMKdxGROKRwFxGJQ4l+7bigoMCVlJT4tXsRkT7p/fff3+ucK+ypnW/hXlJSwrJly/zavYhIn2Rmn4bTTt0yIiJxSOEuIhKHFO4iInFI4S4iEocU7iIicajHcDezh81sj5l9fJjvzczuN7MNZrbCzCZFvkwRETka4Zy5PwLMPML3FwEjg8tc4H+OvywRETkePYa7c+4tYN8RmswCHnOeJUCumQ2MVIGH2LYU3voJbHoDGmt6bTciIn1ZJG5iKgK2hXwuC67b2bWhmc3FO7tnyJAhx7a3rYtg4V3tW4T+o2HwZCgOLvkjIUGXEkTkxBbVO1Sdc/OAeQClpaXH9mTuaTfBpL+F7e9D2TIoWwqrfgfvP+J9n1EIIz8Pp14EI2ZAckaEqhcR6TsiEe7bgcEhn4uD63pPWh6cfIG3ALS1QcUGKHsPNr4Oa/8Ay5+AQAoM/yycMtML++xBvVqWiEisiES4LwBuNLP5wFlAlXPukC6ZXpWQAIWneMvEr0JrM2xdDOtegXUvwSd/ghdvhswBXsBnFwWX4PucIq87J6MAzKJauoicWKrqmslOS8R6OWt6DHczexKYDhSYWRnwQyAJwDn3S+Al4AvABqAOmNNbxYYtkATDzvWWz/8blK+DT16FvZ9A9Q6o2Aib34LG6oN/l9YPCk+D/qd5r4WnQuEoyOyv0BeR4+Kc4/fLd/Cvf1jFHV8czeUTi3t1fz2Gu3Pumh6+d8C3IlZRpJl5Yd3/tEO/a6iGmp1QuQ32rofytd5fBB8/Bw1Vne1Sc7sJ/dMga6BCX0R6tKOynh/8biWvrytnwuBcxgzK6fV9+jblb0xIzfaWwlNh5AWd652D2t1e2O9Z2xn6q38P9Y90tkvJCQZ9MOzb/wLILlLoiwhtbY4n/vop97y8ljYHd1wymmunlhBI6P18OLHD/XDMIOskbxk+vXO9c3BgL5Sv8UJ/7zov9Ne9DB8+3tkuOQvyh0PeMOg3HPoNC74fBlmDNFRT5ASwYU8ttz2/gqVb9nPOyAL+/fKxDO6XHrX9K9yPhhlkFnrLsHMP/u7AXi/oy4Nn+hUbYdcKWPtHaGvpbJeYCieNheIzobgUBp+pM32RONLc2sa8tzZx32ufkJYc4Kezx3PFpKJev4DalcI9UjIKvKVk2sHrW1ugugz2bYZ9m7zQ3/EBLPs1LHnAa5M10Av6IVNg1KWQO/jQ7YtIzPtw635ufW4l63bXcPHYgfzo0jEUZqX4Uot510Ojr7S01J3Qj9lrbYbdH3vTKZQt9cbo79/ifTd0Goy7EkbP8sb0i0hMq21s4aevruPRxVs4KTuVO2edzoWjB/TKvszsfedcaY/tFO4xZP8WWPkMfPQUVHwCgWQY+TkYd5X3mpTqd4Ui0sVrq3fzL7//mF3VDVw7pYTvfu4UslKTem1/Cve+zDnYuRxWPA0rn4UDe8ASQm7CGgTZxZ3vc4d4F2x1E5ZIVDS3trF+dw0Pvr6RF1fu5NQBWfzHFWOZNKT3/6WtcI8XrS2w+U3YugRqdkDVdu9GrOrt0FR7cNvkLOhX0jkyp9/wzvfZRZAQ8OWPINKX1TQ0s2ZnDat3VLFqRzWrd1bzye5amlrbSE5M4KbzRzL33OEkBaIzCi7ccNcF1VgXSISTz/eWrhqqvZCv3OpdrN23GfZvhj1rYP0r0NoUsp1k7ww/NPDbX3OHqstHJERjSyt/Xr2bp5Zu450Ne2k/B87PSGb0oGzmfKaEMYNymFySx8CcNH+LPQyFe1/WfhNW/1GHftfW6gV/e+C3j9bZvxk+XQxNoXPhm3dm328Y5JV4Yd8++ie9oPN9aq66fSSurd9dw1NLt/H8B2Xsr2umKDeNb00/mUlDvbtK+2elRH1I47FSuMerhIB3pp47BPjswd85B3UVIcEfcta//lWvj7/bbSZ6AZ+SFVyyQ95nQd7Qzjt1cwbrZi2Jac2tbeyqamBHZT2f7Knl+Q/K+GBrJUkB43OjT+LKyYP5zMkFUbmbtDco3E9EZp1n44MnH/p9S6N3U1bd3uBrBRwo9943VHpPwGpfqsu81/pK77t2SelQcMqhc/LkDlXfv0TVnuoGPiqrYmVZJVsq6theWc+Oynp2VzfQFnLJ8eT+mdx+8Sgun1hEfqY/Y9MjSeEuh0pM8aZBzik6ut/V7eucgK19Tp7Nb8GK+SHbToOCkSETsJ3a2fevB6vIcapuaObjsiqWl1WyYlsVH5VVsrOqAYAEg+K8dAblpjJ1RAFFuakU5aUxKDeN4rx0SvLT+0yXSzgU7hI56f1gyNneEqqhCsrXe3PytE/RsHUxrHz64HaZAw4e6TNgDJSc411XEOmitrGFVdurWLm9ihVl3uvmvQc6vh+an87kkn6MK85h/OBcxgzKJj35xIm8E+dPKv5JzfG6f7p2ATXWeHPsd1zwDfb7b3oTPnrSa5OQ6M3DM+I8OPk8GDhB3TonoPKaRlbvrGbNzmpW76hm1Y4qNu090DGKZVBOKmOLc/jyGcWcXpTD+OIcctOT/S3aZxrnLrGpqc57Tu7GhbDxL7DzI299Wj9vps6Tz4fhM46+60hiknOOyrpmdlTVs7OygZ1V9ZTtr2fNrhpW76hmb21jR9ui3DRGDcxmXHEOY4tzGFuUQ0Ec9JGHSzcxSXw5sNd7Pu7Ghd5Su8tbX3gajDjfO7MfOhWSozelqoSvobmVHZX17KhsYEdVffB95+edlQ3UN7ce9JvkQAIn989k9KBsRg3MZvTAbEYNzNIZucJd4pZzsGc1bPiLF/SfLoLWRu+B6EPOgv5jQm7SGu4NB008sQMhktraHNUNzeyva6ayronKumb21zWxv66ZfQca2XegiYraJioONAXfN1Ld0HLIdvpnpTAwN42i3FQG5qQxMCeVotw0BuamMSgnlYLMFBL66DDE3hTRcDezmcB9QAD4lXPu7i7fDwUeBgqBfcBXnXNlR9qmwl0ipqkOti6CDQthy9vetMrNnRfWsARvLp7CU+DkC+CUmV74n4Ba2xzV9c1U1TdTWe+FcmVdE/sPeEG9v85bX9fYQn1zKw3NrdQ3t9HY3Ep9cyt1Ta1UNzRzuNgIJBh56cnkZyTTLyOZfpnJFGQkU5iVwqBcb2TKoJw0BuSkkJKoayfHImLhbmYBYD1wIVAGLAWucc6tDmnzDPBH59yjZnYeMMc597UjbVfhLr3GOajd03mhtv1153JvqCZ4Dz4/9SI49QtQdEbc3HC1t7aR9btqWLe7hvW7a9i6r47KOi/Mq+qbqenmDLqdGeSmJZGbnkxGSoDUxABpyQFSEgOkJiWQluR9zgm2yUtPIje9/b33OTs1SWfbvSySc8ucCWxwzm0Kbng+MAtYHdJmNHBz8P3rwAtHV65IBJlB1gBv6Toss2KjN+/Oupfh3fvgnXsho9AL+XFXwpCpMRv0rW2OfQeaKK9ppLy20XutaWRXVT3rd9eyfncNFQc65xPKS0+ipCCDAdmpnDIgi5y0pIOWzmBOol9GsoI5zoQT7kXAtpDPZcBZXdp8BHwJr+vmciDLzPKdcxURqVIkUvJHwJRveUv9fq/fft1L8PFz8MGjXvfN2C97QT9gTLebcM7R2NJGfZN3ATAhwUgwr0siwbwlkGDHdNt6XVMLW/bW8WnFATZXHGDL3gPe530HKK9pPOiOynaZKYmc3D+TC0YN4JSTsjh1QBannJRJYWbfmQdFIi9S49y/B/zCzK4D3gK2A61dG5nZXGAuwJAhQyK0a5FjlJbnBfnYL0NTHY2r/kjTh/PJWPQLEt79b3amjmBh0nQWubGsax1IZXMi9U1eX3R3IdtVgkFiIIHkQAKJASMp+N7MuyjZ6hytbdDmHK1tjrY2R03jwd0mhVkplOSnc+7IQgbmpFKYlUJBZgqFWSkd7zNSdLuKHCqcPvcpwI+cc58Pfr4NwDn3H4dpnwmsdc4VH2m76nOXaGpubaOmoaVjCN7O4IRRO4Kv2/bVsafGG0vdj2ouDixhdtIixuH10bdh7E8exN704VRmDKcmawR12SOoS+1PXWIubZboBbTrDOuW1jaaWh3NrW0HvW9rcyQkGAEz7zWBjvf5GcmUFGRQkp9BSUEGmQpu6SKSfe5LgZFmNgzvjPxq4G+67KwA2OecawNuwxs5IxJxDc2t7KxqoLymkYraRvYGh9p5Q++81wNNLdQ1tVLf1Nrx2tTadsi2kgMJDMxNZVBOGueeUsiwggyG5qdTkp/B0Pwve49K278FdnxIQvk68svXkr9nLexcAtubD95Yak7n9MjpBV5//4AxcNJ471Xj7yXKegx351yLmd0IvIo3FPJh59wqM7sTWOacWwBMB/7DzBxet8y3erFmiTPtw/Pah+ZV1TVTWe9dONxR2X6G7d3oEnrBMFReehL5mSn0S0+mf1YqackB0pMCpCcHSEtOJD05QFZqIgNzUhmUm8bAnDTyM5J7voCYV+ItBxXc7I2+2bsOanfDgYqQGTT3en8hfPoOLAue41iCN0PmSeNg4Hg46XRvtE5mf82PL71GNzFJxDnnjeoo2+/dQr6jst4bTx0cjldd39wxPK+yrqnbG1zaZaUkemEcvNGl/YaX/tkp5GekUJCZTF5GctQecRY256BqG+xc4U2dsGuF975mR2eb1NzO2TH7j/Jei0o1UZocke5QlW41trSyo7KBXVUNtLS1BfuJvQt7ne8dLW1ttLQ6WtqCS6v3uTm4vrm1jabWkPctbeyubugI9K63kicmmDcELz1kKF7HkLzk4LC84PvguvxMb3heXKkth90fe+Pt97TPkrnGG7kD3pTIYy6DiV+FodN0Zi+H0DNUTyDOOeqbW0POhjvPindUemG7bX8dZfvr2VXdcNi7C4+GmddnnRRIICk4EqQwK4XhhRmce0ohxXneHNmD+3l3JWalJGpYHkBmIWTOgBEzOtc553Xp7FkFq17whmV+9KQ3dcKEr8CEv4HsQf7VLH2SztxjSEtrG9UNLR13E4Yu1fWh83g0U1V/8Pvm1u7/d0wwvO6MvDQG56VTnJfG4H7pDMxJJTkxoXNMthkJCXS8TwwkkJhgJAaMxITO90nBQO+rjx7rE5rqYM0C+OBxr+/eErxpE8ZcDiM/Dxn5flcoPtKZe5Q552hobqO6wQviiuCdhHtqOu8kLK9tZG9NIw3NrTS2eN0a7V0aTS1ttPQweDotKXBQ18XJ/TPJTU8iJy05+Brs6gjp+uif5YW49CHJ6TD+am+p2AjL/w+WPwmf/MkL+uIzg1MnXORdqNW/iKQbOnMPamxpZW+tN6xub20je2uaKK9tpLKuiYbmNhpbWjteG1vavAmVmlqpbmihur6Z6obmw549JwWMwszOm07SkgMkJyaQkujd1JKc6J0NpyYFyE5N7Ajn7NTOkM5OSyI1SRMtnbDa2ry5cda/4t1Ru2ult77fcG/qhMnfOGEnQzvR6IIqXmCv3VnDirJKVm6voqK2ifrg7Hb1TZ2vdU2t1DZ2P2KjfbKklGAYpyYF3ycFSEvyJlHKSk0kOxjG2WmJZKUmkR+cCa8wM4Xc9CT1N0tkVW7zgn79K96Tq1yr120z7R9h4Di/q5NeFLfhXtvYQmWd18fc3qXR3NrW8Xn7/no+KqtkRVkVa3dVd5xN52ckc1JOKunJAVKDwZyWHOj4nJ+RTEFmCvmZ3vC6gszOs2yRmFa9E5Y86I2rb6r1+uc/8x2NtolTcRvuv3xzI3e/vPaIbbJSEhlbnMO44lzGFecwrjiHotw0nT1LfKvfD0t/DUv+x7uZqqgUptzgPakqLdfv6iRC4jbc1+ysZuX2qoOH4QX7rpMCCeRnJjMsP0NTl8qJq7neuwj77v1Q+SlYAIpLvUcRjjgfiibpIeN9WNyGu4iEqbUFyt7zHkW44S+w40PAefPgDJ8OJefA4DO9xxIGNHCur1C4i8jB6vbBpuBDxjcs7JwKISkdBk2E4smdS9YAf2uVw9I4dxE5WHo/OP0Kb3EOKrdC2dLOZfED0Bac7bLglM5unJJpkJzhb+1y1HTmLiKe5gZvgrOtS2DTG/Dpu9DSAIFk73GFI87zlgFjY/ZRhCcCdcuIyPFpboCtizq7cfas8tan5nrDLEumQclnYMDpukAbReqWEZHjk5Taebb+Obzx9JvfhC1vw5Z3Yd2LXruUHBg6FU4+35vkTF04MUFn7iJybKq2e103W97xln0bvadQTf0HbzqElEy/K4xL6pYRkeja9h68cTds/Auk9YOpN8KZcyEly+/K4kq44a6rIiISGYPPhK89D19/DYrOgL/cCf89Ft76CTRU+13dCUfhLiKRNXgyfPVZ+MZCb3rihXfBfePg3fu8ueolKsIKdzObaWbrzGyDmd3azfdDzOx1M/vQzFaY2RciX6qI9CnFZ8BXnoZvvu7Nc/PnO+D+ibD0V9DS/YPOJXJ6DHczCwAPABcBo4FrzGx0l2a3A0875yYCVwMPRrpQEemjiiZ5Z/JzXvbmnH/xu/CLUu8BJG2tPf9ejkk4Z+5nAhucc5ucc03AfGBWlzYOaH9kew6wAxGRUEOnegH/lee8+W1euB7+Zyqse5mIPNhXDhJOuBcB20I+lwXXhfoR8FUzKwNeAv4hItWJSHwxg5EXwNw3Yfaj3pn7k1fDE1+CPUeeyluOTqQuqF4DPOKcKwa+ADxuZods28zmmtkyM1tWXl4eoV2LSJ+TkABjLoMbFsPMe2D7+95Z/Mu3evPSy3ELJ9y3A4NDPhcH14X6OvA0gHNuMZAKFHTdkHNunnOu1DlXWlhYeGwVi0j8CCTB2dfDP3wIZ1wH7z0E90/yLrq2dv/oSwlPOOG+FBhpZsPMLBnvgumCLm22AucDmNkovHDXqbmIhCcjHy65F/7f2zBgjHfR9aFzYe8nflfWZ/UY7s65FuBG4FVgDd6omFVmdqeZXRps9l3gm2b2EfAkcJ3z69ZXEem7Tjodrv0DXPkY1O6GRy6G8vV+V9UnafoBEYlNe9bCo1/03l/3Ryg81d96YoSmHxCRvq3/aXDdi94Im0cuhj1r/K6oT1G4i0jsKjwlGPABeOQS2L3a74r6DIW7iMS2gpFewAeS4NFLYNfHflfUJyjcRST2FZzsBXxiqtcPv2ul3xXFPIW7iPQN+SO8C6tJ6V7Ab3/f74pimsJdRPqOfsNhzove3DSPXgqb3/a7opilcBeRviWvBOa8AjmD4YkrvInH5BAKdxHpe7IHwpyXvLtZ538FVjztd0UxR+EuIn1Tej+4doE3lfDzc+G9//W7opiicBeRvislC77yLJwyE176Hrz9M80NH6RwF5G+LSkVrnocxl7pPZT7tR8p4IFEvwsQETlugSS4/CFIyYR3/9ubsuD8H3qvJyiFu4jEh4QEuPhe76z9nf+ChCQ47wd+V+UbhbuIxA8zL+DbWuCt/4SERJj+z35X5QuFu4jEl4QE+OL93vNZ3/h3SAjAud/zu6qoU7iLSPxJSIBZv/DO4Bf+2OuTn3aT31VFlcJdROJTQgAu+x9wrfDnO7wuminf8ruqqFG4i0j8CiTC5fO8M/hXv+9NOlY6x++qokLhLiLxLZAIV/wamurgpX+CAafD4Ml+V9XrwrqJycxmmtk6M9tgZrd28/1/mdny4LLezCojX6qIyDEKJMEV/+vNSfPMtXBgr98V9boew93MAsADwEXAaOAaMxsd2sY59x3n3ATn3ATg58DzvVGsiMgxS8uDKx/3gv25b3ijaeJYOGfuZwIbnHObnHNNwHxg1hHaXwM8GYniREQiatAE+MJPYNPr8MbdflfTq8IJ9yJgW8jnsuC6Q5jZUGAYsPAw3881s2Vmtqy8vPxoaxUROX6T/hYmfNW7yWn9q35X02siPXHY1cCzzrlu/73jnJvnnCt1zpUWFhZGeNciImEwg4t/CgPGelMF79/id0W9Ipxw3w4MDvlcHFzXnatRl4yIxLqkNLjqMW8emqf/Fpob/K4o4sIJ96XASDMbZmbJeAG+oGsjMzsNyAMWR7ZEEZFe0G84XP5L2PkRvHyL39VEXI/h7pxrAW4EXgXWAE8751aZ2Z1mdmlI06uB+c5pImUR6SNO+wJ85mb44FFY9YLf1USU+ZXFpaWlbtmyZb7sW0SkQ2sLzJsODZVw41KvyyaGmdn7zrnSntrpSUwicmILJMJFd0PVNlj0c7+riRiFu4hIyWdg9CzvIR9Vhxsv0rco3EVEAC78sXfX6ms/8ruSiFC4i4gA5A2Fad+GlU/D1r/6Xc1xU7iLiLSb9o+QNRBe+Wdoa/O7muOicBcRaZeSCRf8K+z4EFbM97ua46JwFxEJNXY2FE/2+t4ba/yu5pgp3EVEQiUkwMx7oHY3vP0zv6s5Zgp3EZGuis+A8dfA4gdg32a/qzkmCncRke6c/0NISII/3e53JcdE4S4i0p3sgXDOzbD2j7DtPb+rOWoKdxGRwzn77yGtH7z1U78rOWoKdxGRw0nOgCnfgk9e9aYG7kMU7iIiR3LmNyElp8+dvSvcRUSOJDUHzvp/sGYB7FnjdzVhU7iLiPTk7L+HpAx4+16/Kwmbwl1EpCfp/WDy1+HjZ6Fio9/VhEXhLiISjik3QiDZm/O9Dwgr3M1sppmtM7MNZnbrYdpcaWarzWyVmf02smWKiPgsawBMuhY+ehIqt/pdTY96DHczCwAPABcBo4FrzGx0lzYjgduAac65McA/9kKtIiL+mvZtwODd+/yupEfhnLmfCWxwzm1yzjUB84FZXdp8E3jAObcfwDm3J7JliojEgJximPA38MHjUL3T72qOKJxwLwK2hXwuC64LdQpwipm9a2ZLzGxmpAoUEYkpn/kOtLXA4l/4XckRReqCaiIwEpgOXAP8r5nldm1kZnPNbJmZLSsvL4/QrkVEoqjfMG/O92UPw4G9fldzWOGE+3ZgcMjn4uC6UGXAAudcs3NuM7AeL+wP4pyb55wrdc6VFhYWHmvNIiL+OudmaK6HJQ/6XclhhRPuS4GRZjbMzJKBq4EFXdq8gHfWjpkV4HXTbIpgnSIisaPwVBh1CSz7Tcw+a7XHcHfOtQA3Aq8Ca4CnnXOrzOxOM7s02OxVoMLMVgOvA//knKvoraJFRHx32hehfh/sis0JxRLDaeScewl4qcu6O0LeO+Dm4CIiEv+GT/deN74Ogyb6WUm3dIeqiMixyBoA/cfAptf9rqRbCncRkWM1YgZsXQJNdX5XcgiFu4jIsRo+A1qbYOsivys5hMJdRORYDZ3qTSa2Mfa6ZhTuIiLHKjkdBp8Fm97wu5JDKNxFRI7H8Omw+2Ooja0ptRTuIiLHY8QM73XTm/7W0YXCXUTkeAycAKm5MTckUuEuInI8EgIw/LPeRVXn/K6mg8JdROR4DZ8BNTtg73q/K+mgcBcROV7t/e4xNCRS4S4icrzySiBvWEz1uyvcRUQiYcQM2PIOtDb7XQmgcBcRiYzhM6CpFsqW+l0JoHAXEYmMYeeCJcRMv7vCXUQkEtJyYdCkmJmKQOEuIhIpI2bA9vehocrvShTuIiIRM3wGuFbY/LbflSjcRUQipngyJGXExJDIsMLdzGaa2Toz22Bmt3bz/XVmVm5my4PLNyJfqohIjEtMhpLPxMRF1R7D3cwCwAPARcBo4BozG91N06eccxOCy68iXKeISN8wYgbs2wiVW30tI5wz9zOBDc65Tc65JmA+MKt3yxIR6aOGx8ZUBOGEexGwLeRzWXBdV1eY2Qoze9bMBkekOhGRvqbwVMgcAFsX+1pGpC6o/gEocc6NA/4MPNpdIzOba2bLzGxZeXl5hHYtIhJDzCD/5D7RLbMdCD0TLw6u6+Ccq3DONQY//go4o7sNOefmOedKnXOlhYWFx1KviEjsyy6Cqm09t+tF4YT7UmCkmQ0zs2TgamBBaAMzGxjy8VJgTeRKFBHpY3KKoHontLX5VkJiTw2ccy1mdiPwKhAAHnbOrTKzO4FlzrkFwLfN7FKgBdgHXNeLNYuIxLbsImhrhgN7IOskX0roMdwBnHMvAS91WXdHyPvbgNsiW5qISB+VE+zJrtruW7jrDlURkUjLCQ4orC7zrQSFu4hIpGUHw71q+5Hb9SKFu4hIpKXlQVI6VOnMXUQkfph5Z+/qlhERiTM5ReqWERGJO9nFUK1wFxGJLznFULMLWpt92b3CXUSkN+QUAQ5qdvqye4W7iEhv6BgO6c9FVYW7iEhvyCn2Xn26qKpwFxHpDdn+3qWqcBcR6Q0pmZCaozN3EZG4kzPYt+GQCncRkd6SXaQLqiIicSdH4S4iEn+yi6B+HzTVRX3XCncRkd7SPhyyekfUd61wFxHpLT4Oh1S4i4j0lhz/HtoRVrib2UwzW2dmG8zs1iO0u8LMnJmVRq5EEZE+yscpCHoMdzMLAA8AFwGjgWvMbHQ37bKAm4C/RrpIEZE+KTEFMvrHbLfMmcAG59wm51wTMB+Y1U27HwP3AA0RrE9EpG/z6aEd4YR7EbAt5HNZcF0HM5sEDHbOvXikDZnZXDNbZmbLysvLj7pYEZE+J7vIl7tUj/uCqpklAPcC3+2prXNunnOu1DlXWlhYeLy7FhGJfTnFMXvmvh0YHPK5OLiuXRZwOvCGmW0BzgYW6KKqiAjemXtTDTRURXW34YT7UmCkmQ0zs2TgamBB+5fOuSrnXIFzrsQ5VwIsAS51zi3rlYpFRPqSjnndo3tRNbGnBs65FjO7EXgVCAAPO+dWmdmdwDLn3IIjbyF8zc3NlJXcEbIsAAAOjUlEQVSV0dCga7LHKjU1leLiYpKSkvwuRUTg4Id2DBgTtd32GO4AzrmXgJe6rLvjMG2nH2sxZWVlZGVlUVJSgpkd62ZOWM45KioqKCsrY9iwYX6XIyLg212qMXWHakNDA/n5+Qr2Y2Rm5Ofn618+IrEk6ySwQNQvqsZUuAMK9uOk4ycSYxICkDUw6sMhYy7cRUTijg/zuivcfdLS0uJ3CSISLT48kUnh3o3LLruMM844gzFjxjBv3jwAXnnlFSZNmsT48eM5//zzAaitrWXOnDmMHTuWcePG8dxzzwGQmZnZsa1nn32W6667DoDrrruO66+/nrPOOotbbrmF9957jylTpjBx4kSmTp3KunXrAGhtbeV73/sep59+OuPGjePnP/85Cxcu5LLLLuvY7p///Gcuv/zyaBwOETleOcXenO7ORW2XYY2W8cO//mEVq3dUR3Sbowdl88Mv9jwU6eGHH6Zfv37U19czefJkZs2axTe/+U3eeusthg0bxr59+wD48Y9/TE5ODitXrgRg//79PW67rKyMRYsWEQgEqK6u5u233yYxMZHXXnuN73//+zz33HPMmzePLVu2sHz5chITE9m3bx95eXnccMMNlJeXU1hYyG9+8xv+7u/+7vgOiIhER04xtDbCgb2QGZ2782M23P10//3387vf/Q6Abdu2MW/ePM4999yO4YX9+vUD4LXXXmP+/Pkdv8vLy+tx27NnzyYQCABQVVXFtddeyyeffIKZ0dzc3LHd66+/nsTExIP297WvfY0nnniCOXPmsHjxYh577LEI/YlFpFeFDoc80cM9nDPs3vDGG2/w2muvsXjxYtLT05k+fToTJkxg7dq1YW8jdMRK12GJGRkZHe//5V/+hRkzZvC73/2OLVu2MH369CNud86cOXzxi18kNTWV2bNnd4S/iMS40Id2DJoYlV2qz72Lqqoq8vLySE9PZ+3atSxZsoSGhgbeeustNm/eDNDRLXPhhRfywAMPdPy2vVtmwIABrFmzhra2to5/ARxuX0VF3v/ojzzySMf6Cy+8kIceeqjjomv7/gYNGsSgQYO46667mDNnTuT+0CLSu7Lbn6UaveGQCvcuZs6cSUtLC6NGjeLWW2/l7LPPprCwkHnz5vGlL32J8ePHc9VVVwFw++23s3//fk4//XTGjx/P66+/DsDdd9/NJZdcwtSpUxk4cOBh93XLLbdw2223MXHixINGz3zjG99gyJAhjBs3jvHjx/Pb3/6247uvfOUrDB48mFGjRvXSERCRiMsogEAKVG3ruW2EmIvi1dtQpaWlbtmyg+cWW7NmjUKrBzfeeCMTJ07k61//+mHb6DiKxKD7JnhdMrN/c1ybMbP3nXM9zrqrTts+5IwzziAjI4Of/exnfpciIkcrpziq3TIK9z7k/fff97sEETlWOcWw+e2o7U597iIi0ZBdBDU7oTU6d6cr3EVEoiGnCFwr1O6Kyu4U7iIi0ZAd8tCOKFC4i4hEQ050H9qhcBcRiYacGDxzN7OZZrbOzDaY2a3dfH+9ma00s+Vm9o6ZjY58qfFFU/6KnGBScyA5K2rDIXsMdzMLAA8AFwGjgWu6Ce/fOufGOucmAP8J3BvxSqPoscce67g79Gtf+xpbtmzhvPPOY9y4cZx//vls3bqVqqoqhg4dSltbGwAHDhxg8ODBNDc3s3HjRmbOnMkZZ5zBOeec0zEvTbhT/tbV1XHllVcyevRoLr/8cs466yzab/j605/+xJQpU5g0aRKzZ8+mtrbWn4MkIkcvig/tCGec+5nABufcJgAzmw/MAla3N3DOhc7NmwEc/22vL98Ku1Ye92YOctJYuOjuIzZZtWoVd911F4sWLaKgoIB9+/Zx7bXXdiwPP/ww3/72t3nhhReYMGECb775JjNmzOCPf/wjn//850lKSmLu3Ln88pe/ZOTIkfz1r3/lhhtuYOHChUB4U/4++OCD5OXlsXr1aj7++GMmTJgAwN69e7nrrrt47bXXyMjI4J577uHee+/ljju6fVa5iMSaKD60I5xwLwJCJ0QoA87q2sjMvgXcDCQD50WkOh8sXLiQ2bNnU1BQAHjT7S5evJjnn38e8KbdveWWWwC46qqreOqpp5gxYwbz58/nhhtuoLa2lkWLFjF79uyObTY2Nna8D2fK33feeYebbroJoOOBHQBLlixh9erVTJs2DYCmpiamTJnSm4dDRCIppwh2rYjKriJ2h6pz7gHgATP7G+B24NqubcxsLjAXYMiQIUfeYA9n2LHg0ksv5fvf/z779u3j/fff57zzzuPAgQPk5uayfPnybn9zPFP+Oue48MILefLJJyP5xxCRaMkuhgPl0NIIiSm9uqtwLqhuBwaHfC4Orjuc+cBl3X3hnJvnnCt1zpUWFkZnwvqjdd555/HMM89QUVEBeNPtTp06teOhHP/3f//HOeecA3iP05s8eTI33XQTl1xyCYFAgOzsbIYNG8YzzzwDeIH80Ucfdbuvw035O23aNJ5++mkAVq9e3fGkp7PPPpt3332XDRs2AF4///r16yN8BESk13QMh+z9i6rhhPtSYKSZDTOzZOBqYEFoAzMbGfLxYuCTyJUYXWPGjOEHP/gBn/3sZxk/fjw333wzP//5z/nNb37DuHHjePzxx7nvvvs62l911VU88cQTHdMAg/cXwK9//WvGjx/PmDFj+P3vf9/tvg435W/74/RGjx7N7bffzpgxY8jJyaGwsJBHHnmEa665hnHjxjFlypSjeoiIiPgsisMhw5ry18y+APw3EAAeds79m5ndCSxzzi0ws/uAC4BmYD9wo3Nu1ZG2qSl/D6+1tZXm5mZSU1PZuHEjF1xwAevWrSM5OTms3+s4isSovRvgF2fA5Q/B+KuPaRMRnfLXOfcS8FKXdXeEvL/pqCuUw6qrq2PGjBk0NzfjnOPBBx8MO9hFJIblFMGpF3sP7+hlmvI3BmVlZdH1XzUiEgeS0uCa3/bcLgI0/YCISByKuXD367F/8ULHT0QgxsI9NTWViooKBdQxcs5RUVFBamqq36WIiM9iqs+9uLiYsrIyysvL/S6lz0pNTaW4uNjvMkTEZzEV7klJSQwbNszvMkRE+ryY6pYREZHIULiLiMQhhbuISBwKa/qBXtmxWTnw6TH+vADYG8Fy+jodj4PpeHTSsThYPByPoc65Hmde9C3cj4eZLQtnboUThY7HwXQ8OulYHOxEOh7qlhERiUMKdxGRONRXw32e3wXEGB2Pg+l4dNKxONgJczz6ZJ+7iIgcWV89cxcRkSOI6XA3s5lmts7MNpjZrd18n2JmTwW//6uZlUS/yugJ43ica2YfmFmLmX3ZjxqjJYxjcbOZrTazFWb2FzMb6ked0RLG8bjezFaa2XIze8fMRvtRZ7T0dDxC2l1hZs7M4m8EjXMuJhe8R/ptBIYDycBHwOgubW4Afhl8fzXwlN91+3w8SoBxwGPAl/2u2edjMQNID77/e/23QXbI+0uBV/yu28/jEWyXBbwFLAFK/a470kssn7mfCWxwzm1yzjUB84FZXdrMAh4Nvn8WON/MLIo1RlOPx8M5t8U5twJo86PAKArnWLzunKsLflwCxPNUmeEcj+qQjxlAPF9sCyc7AH4M3AM0RLO4aInlcC8CtoV8Lguu67aNc64FqALyo1Jd9IVzPE4UR3ssvg683KsV+Sus42Fm3zKzjcB/At+OUm1+6PF4mNkkYLBz7sVoFhZNsRzuIsfNzL4KlAI/8bsWvznnHnDOjQD+Gbjd73r8YmYJwL3Ad/2upTfFcrhvBwaHfC4Oruu2jZklAjlARVSqi75wjseJIqxjYWYXAD8ALnXONUapNj8c7X8b84HLerUif/V0PLKA04E3zGwLcDawIN4uqsZyuC8FRprZMDNLxrtguqBLmwXAtcH3XwYWuuCVkjgUzvE4UfR4LMxsIvAQXrDv8aHGaArneIwM+Xgx8EkU64u2Ix4P51yVc67AOVfinCvBuyZzqXNumT/l9o6YDfdgH/qNwKvAGuBp59wqM7vTzC4NNvs1kG9mG4CbgcMOeerrwjkeZjbZzMqA2cBDZrbKv4p7T5j/bfwEyASeCQ7/i9u/CMM8Hjea2SozW473/5VrD7O5Pi/M4xH3dIeqiEgcitkzdxEROXYKdxGROKRwFxGJQwp3EZE4pHAXEYlDCneJG2b2j2aWfoTvf3Wk2RDNbLqZTe2d6kSiS0MhJW4E7zYsdc4d8nR7Mws451p7+P2PgFrn3E97p0KR6NGZu/RJZpZhZi+a2Udm9rGZ/RAYBLxuZq8H29Sa2c/M7CNgipm90X6LeXC+7w+Cv/9L8FkA1wPfCd70dI6ZPWJm95vZIjPbFDpHvpn9k5ktDc4X/6+Hqemq4Pq7Q+aW118cEhWJfhcgcoxmAjuccxcDmFkOMAeYEXLmngH81Tn33WAbgq+FwP8C5zrnNptZP+fcPjP7JSFn7mb2dWAg8BngNLxb2J81s88BI/GmljW8eUnOBQq71mRm+cDlwGnOOWdmub17WEQ8OnOXvmolcKGZ3WNm5zjnqrpp0wo81836s4G3nHObAZxz+46wnxecc23OudXAgOC6zwWXD4EP8IJ/5GFqqsKbL/zXZvYloO6QPYj0Ap25S5/knFsfnJP7C8BdZvaXbpo19NTPHobQ2SQt5PU/nHMPdW3ctSbn3J1mdiZwPt7kdjcC5x1nTSI90pm79ElmNgioc849gTdJ2CSgBm86154sAc41s2HBbfULrg/3968Cf2dmmcHfF5lZ/+5qCrbJcc69BHwHGB/2H1LkOOjMXfqqscBPzKwNaMZ7TuoU4BUz2+Gcm3G4Hzrnys1sLvB88MENe4ALgT/g9anPAv7hCL//k5mNAhYH+/Frga8CJ3dTUxbwezNLxTvjv/k4/9wiYdFQSBGROKRuGRGROKRwFxGJQwp3EZE4pHAXEYlDCncRkTikcBcRiUMKdxGROKRwFxGJQ/8f6FDp/UV5OQUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(zip(y_pred_prob.T[0].T,y_pred,y_actual))\n",
    "test_df.columns = ['y_pred_prob','y_pred','y_actual']\n",
    "test_df['correct'] = y_pred==y_actual\n",
    "test_df['correct'] = test_df['correct'].apply(int)\n",
    "\n",
    "strictness = [x/100 for x in range(0,50)]\n",
    "\n",
    "coverages = []\n",
    "accuracies = []\n",
    "for strictness_thres in strictness:\n",
    "    this_coverage = test_df[abs(test_df.y_pred_prob-0.5) >= strictness_thres].correct.count()/len(test_df)\n",
    "    this_accuracy = test_df[abs(test_df.y_pred_prob-0.5) >= strictness_thres].correct.mean()\n",
    "    coverages.append(this_coverage)\n",
    "    accuracies.append(this_accuracy)\n",
    "    \n",
    "cov_accu_df = pd.DataFrame()\n",
    "cov_accu_df['strictness'] = strictness\n",
    "cov_accu_df['coverage'] = coverages\n",
    "cov_accu_df['accuracy'] = accuracies\n",
    "\n",
    "cov_accu_df.dropna(inplace = True)\n",
    "\n",
    "cov_accu_df.plot('strictness',['accuracy','coverage'])\n",
    "\n",
    "# strictness_thres_hold = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test on all posts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts = pd.read_csv('data/all_posts_detailed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_posts = all_posts[all_posts.read_count>=1000].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_posts['title_body'] = key_posts['post_title']+key_posts['post_body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of all posts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303789\n"
     ]
    }
   ],
   "source": [
    "print(len(key_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # remove punctuations\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    # cut words\n",
    "    cut = jieba.cut(text)\n",
    "    cut_list = [ i for i in cut ]\n",
    "    # tokenize\n",
    "    for i, word in enumerate(cut_list):\n",
    "        try:\n",
    "            cut_list[i] = cn_model.vocab[word].index\n",
    "            if cut_list[i] >= 100000:\n",
    "                cut_list[i] = 0\n",
    "        except KeyError:\n",
    "            cut_list[i] = 0\n",
    "    # padding\n",
    "    tokens_pad = pad_sequences([cut_list], maxlen=max_tokens, padding='pre', truncating='pre').flatten()\n",
    "    return tokens_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_pad_list = key_posts['title_body'].apply(preprocess_text).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = np.stack(tokens_pad_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "result = model.predict(x=new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_posts['pred_sentiment'] = result.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of posts with prob = 0.9 confidence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113019"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.abs(key_posts['pred_sentiment']-0.5)>=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of posts with prob = 0.75 confidence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212351"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.abs(key_posts['pred_sentiment']-0.5)>=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of posts with prob = 0.75 confidence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91438"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.abs(key_posts['pred_sentiment']-0.5)<=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_posts['lstm_sentiment'] = key_posts['pred_sentiment']>=0.5\n",
    "key_posts['lstm_sentiment'] = key_posts['lstm_sentiment'].apply(int)\n",
    "key_posts['lstm_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_posts['sentiment_pred_category'] = np.nan\n",
    "\n",
    "key_posts.loc[np.abs(key_posts['pred_sentiment']-0.5)<=0.25,'sentiment_pred_category'] = 0\n",
    "\n",
    "key_posts.loc[np.abs(key_posts['pred_sentiment']-0.5)>=0.25,'sentiment_pred_category'] = 1\n",
    "\n",
    "key_posts.loc[np.abs(key_posts['pred_sentiment']-0.5)>=0.4,'sentiment_pred_category'] = 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
